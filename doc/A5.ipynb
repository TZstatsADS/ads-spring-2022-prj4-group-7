{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c2f9ca2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:32:37.405139Z",
     "start_time": "2022-04-07T06:32:35.054155Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import Sequential,regularizers\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b25c65",
   "metadata": {},
   "source": [
    "# Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46c4520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:32:37.443337Z",
     "start_time": "2022-04-07T06:32:37.406198Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/compas-scores-two-years.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a5843",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d428b1",
   "metadata": {},
   "source": [
    "## Chose useful rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e2b1782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:32:37.457651Z",
     "start_time": "2022-04-07T06:32:37.445442Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6129, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.loc[data['race'].isin(['African-American','Caucasian'])]\n",
    "data=data[[ 'sex','age', 'race', 'priors_count',\n",
    "             'c_charge_degree', 'c_charge_desc',\n",
    "             'start', 'end', 'event', 'two_year_recid']]\n",
    "data = data.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d1296f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:32:37.465536Z",
     "start_time": "2022-04-07T06:32:37.459257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>c_charge_desc</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Felony Battery w/Prior Convict</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>African-American</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>Possession of Cocaine</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>Possession of Cannabis</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>Possession Burglary Tools</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>Battery</td>\n",
       "      <td>2</td>\n",
       "      <td>747</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex  age              race  priors_count c_charge_degree  \\\n",
       "1    Male   34  African-American             0               F   \n",
       "2    Male   24  African-American             4               F   \n",
       "3    Male   23  African-American             1               F   \n",
       "6    Male   41         Caucasian            14               F   \n",
       "8  Female   39         Caucasian             0               M   \n",
       "\n",
       "                    c_charge_desc  start   end  event  two_year_recid  \n",
       "1  Felony Battery w/Prior Convict      9   159      1               1  \n",
       "2           Possession of Cocaine      0    63      0               1  \n",
       "3          Possession of Cannabis      0  1174      0               0  \n",
       "6       Possession Burglary Tools      5    40      1               1  \n",
       "8                         Battery      2   747      0               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518dc677",
   "metadata": {},
   "source": [
    "## Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "806a7664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:32:37.467825Z",
     "start_time": "2022-04-07T06:32:37.466311Z"
    }
   },
   "outputs": [],
   "source": [
    "label = data['two_year_recid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80efb412",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:32:37.471295Z",
     "start_time": "2022-04-07T06:32:37.468496Z"
    }
   },
   "outputs": [],
   "source": [
    "sf = (data[['race']]=='Caucasian').astype(int)\n",
    "sf.index = range(sf.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934106f0",
   "metadata": {},
   "source": [
    "## Normalize numerical columns and encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b850468",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:32:37.476357Z",
     "start_time": "2022-04-07T06:32:37.472169Z"
    }
   },
   "outputs": [],
   "source": [
    "num = data._get_numeric_data()\n",
    "num = num.drop(labels='two_year_recid',axis=1)\n",
    "ss = StandardScaler()\n",
    "num_ss = ss.fit_transform(num)\n",
    "num = pd.DataFrame(num_ss,columns=num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fda9b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:32:37.489645Z",
     "start_time": "2022-04-07T06:32:37.478213Z"
    }
   },
   "outputs": [],
   "source": [
    "num_cols = data._get_numeric_data().columns\n",
    "cat = data.drop(columns = num_cols, axis = 1)\n",
    "cat = cat.drop(labels='race',axis=1)\n",
    "cat = pd.get_dummies(cat)\n",
    "cat.index = range(cat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "facb4f0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:32:37.492350Z",
     "start_time": "2022-04-07T06:32:37.490368Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_data = pd.concat([sf,cat,num], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe5be47",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33b0fd2",
   "metadata": {},
   "source": [
    "## Basemodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854d44e2",
   "metadata": {},
   "source": [
    "### Get train, validation, test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a56674",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:32:37.506802Z",
     "start_time": "2022-04-07T06:32:37.492971Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(clean_data,label,test_size=1/7)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=1/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee542489",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:32:38.826029Z",
     "start_time": "2022-04-07T06:32:37.507656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100. \n",
      "Test - Loss: 341.6089172363281. Accuracy: 91.0958904109589\n",
      "Train -  Loss: 2510.0908203125. Accuracy: 91.61526159469956\n",
      "\n",
      "Iteration: 200. \n",
      "Test - Loss: 348.3466796875. Accuracy: 90.8675799086758\n",
      "Train -  Loss: 2397.07958984375. Accuracy: 91.70664838930774\n",
      "\n",
      "Iteration: 300. \n",
      "Test - Loss: 354.2894287109375. Accuracy: 90.98173515981735\n",
      "Train -  Loss: 2307.4599609375. Accuracy: 91.75234178661184\n",
      "\n",
      "Iteration: 400. \n",
      "Test - Loss: 359.0176086425781. Accuracy: 90.8675799086758\n",
      "Train -  Loss: 2233.6845703125. Accuracy: 91.77518848526388\n",
      "\n",
      "Iteration: 500. \n",
      "Test - Loss: 362.7321472167969. Accuracy: 90.6392694063927\n",
      "Train -  Loss: 2173.404296875. Accuracy: 91.82088188256797\n",
      "\n",
      "Iteration: 600. \n",
      "Test - Loss: 365.6965637207031. Accuracy: 90.52511415525115\n",
      "Train -  Loss: 2121.65576171875. Accuracy: 91.84372858122002\n",
      "\n",
      "Iteration: 700. \n",
      "Test - Loss: 368.06170654296875. Accuracy: 90.6392694063927\n",
      "Train -  Loss: 2078.51416015625. Accuracy: 91.93511537582819\n",
      "\n",
      "Iteration: 800. \n",
      "Test - Loss: 369.8584289550781. Accuracy: 90.52511415525115\n",
      "Train -  Loss: 2040.9774169921875. Accuracy: 92.02650217043637\n",
      "\n",
      "Iteration: 900. \n",
      "Test - Loss: 371.10382080078125. Accuracy: 90.52511415525115\n",
      "Train -  Loss: 2008.029541015625. Accuracy: 92.11788896504456\n",
      "\n",
      "Iteration: 1000. \n",
      "Test - Loss: 371.8629455566406. Accuracy: 90.52511415525115\n",
      "Train -  Loss: 1978.652099609375. Accuracy: 92.1407356636966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = torch.sigmoid(self.linear(x))\n",
    "        return outputs\n",
    "\n",
    "epochs = 1000\n",
    "input_dim = 420 \n",
    "output_dim = 1 \n",
    "learning_rate = 0.01\n",
    "\n",
    "model = LogisticRegression(input_dim,output_dim)\n",
    "criterion = nn.BCELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "X_train, X_test = torch.Tensor(np.array(X_train)),torch.Tensor(np.array(X_test))\n",
    "y_train, y_test = torch.Tensor(np.array(y_train)),torch.Tensor(np.array(y_test))\n",
    "\n",
    "losses = []\n",
    "losses_test = []\n",
    "Iterations = []\n",
    "iter = 0\n",
    "for epoch in range(epochs):\n",
    "    x = X_train\n",
    "    labels = y_train\n",
    "    optimizer.zero_grad() # Setting our stored gradients equal to zero\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(torch.squeeze(outputs), torch.tensor(np.array(labels))) # [200,1] -squeeze-> [200]\n",
    "    loss.backward() # Computes the gradient of the given tensor w.r.t. graph leaves \n",
    "    optimizer.step() # Updates weights and biases with the optimizer (SGD)\n",
    "    \n",
    "    iter+=1\n",
    "    if iter%100==0:\n",
    "        # calculate Accuracy\n",
    "        with torch.no_grad():\n",
    "            # Calculating the loss and accuracy for the test dataset\n",
    "            correct_test = 0\n",
    "            total_test = 0\n",
    "            outputs_test = torch.squeeze(model(X_test))\n",
    "            loss_test = criterion(outputs_test, torch.tensor(np.array(y_test)))\n",
    "            \n",
    "            predicted_test = outputs_test.round().detach().numpy()\n",
    "            total_test += y_test.size(0)\n",
    "            correct_test += np.sum(predicted_test == y_test.detach().numpy())\n",
    "            accuracy_test = 100 * correct_test/total_test\n",
    "            losses_test.append(loss_test.item())\n",
    "            \n",
    "            # Calculating the loss and accuracy for the train dataset\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            total += y_train.size(0)\n",
    "            correct += np.sum(torch.squeeze(outputs).round().detach().numpy() == y_train.detach().numpy())\n",
    "            accuracy = 100 * correct/total\n",
    "            losses.append(loss.item())\n",
    "            Iterations.append(iter)\n",
    "            \n",
    "            print(f\"Iteration: {iter}. \\nTest - Loss: {loss_test.item()}. Accuracy: {accuracy_test}\")\n",
    "            print(f\"Train -  Loss: {loss.item()}. Accuracy: {accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e36fa",
   "metadata": {},
   "source": [
    "## Model with PR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae784ba",
   "metadata": {},
   "source": [
    "### Get train, validation, test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c3be9b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:35:20.896450Z",
     "start_time": "2022-04-07T06:35:20.859614Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(clean_data,label,test_size=1/7)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=1/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "671bb742",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:35:21.343525Z",
     "start_time": "2022-04-07T06:35:21.339324Z"
    }
   },
   "outputs": [],
   "source": [
    "class PrejudiceRemover(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        N = inputs.shape[0]\n",
    "        N_s1 = inputs[inputs[:,0]==1].shape[0]\n",
    "        N_s0 = inputs[inputs[:,0]==0].shape[0]\n",
    "        \n",
    "        P_ys1 = torch.sum(model(inputs[inputs[:,0]==1])) / N_s1\n",
    "        P_ys0 = torch.sum(model(inputs[inputs[:,0]==0])) / N_s0\n",
    "        P_y = torch.sum(model(inputs)) / N\n",
    "        \n",
    "        P_y1s1 = torch.log(P_ys1) - torch.log(P_y)\n",
    "        P_y0s1 = torch.log(1-P_ys1) - torch.log(1-P_y)\n",
    "        P_y1s0 = torch.log(P_ys0) - torch.log(P_y)\n",
    "        P_y0s0 = torch.log(1-P_ys0) - torch.log(1-P_y)\n",
    "        \n",
    "        PI_y1s1 = torch.sum(model(inputs[inputs[:,0]==1]) * P_y1s1)\n",
    "        PI_y0s1 = torch.sum((1- model(inputs[inputs[:,0]==1])) * P_y0s1)\n",
    "        PI_y1s0 = torch.sum(model(inputs[inputs[:,0]==0]) * P_y1s0)\n",
    "        PI_y0s0 = torch.sum((1- model(inputs[inputs[:,0]==0]))* P_y0s0)\n",
    "        \n",
    "        PI = PI_y1s1 + PI_y0s1 + PI_y1s0 + PI_y0s0\n",
    "        return PI\n",
    "        \n",
    "pr = PrejudiceRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c9595fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:35:33.423640Z",
     "start_time": "2022-04-07T06:35:21.669928Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.7766)\n",
      "tensor(5.7766)\n",
      "Iteration: 100. \n",
      "Test - Loss: 523.0494384765625. Accuracy: 90.6392694063927\n",
      "Train -  Loss: 1605.1719970703125. Accuracy: 91.24971441626685\n",
      "\n",
      "tensor(5.6252)\n",
      "tensor(5.6252)\n",
      "Iteration: 200. \n",
      "Test - Loss: 512.8511352539062. Accuracy: 90.75342465753425\n",
      "Train -  Loss: 1567.66162109375. Accuracy: 91.18117432031072\n",
      "\n",
      "tensor(5.6147)\n",
      "tensor(5.6147)\n",
      "Iteration: 300. \n",
      "Test - Loss: 587.6864624023438. Accuracy: 90.98173515981735\n",
      "Train -  Loss: 1541.3040771484375. Accuracy: 91.2725611149189\n",
      "\n",
      "tensor(5.6582)\n",
      "tensor(5.6582)\n",
      "Iteration: 400. \n",
      "Test - Loss: 580.1775512695312. Accuracy: 91.0958904109589\n",
      "Train -  Loss: 1518.2100830078125. Accuracy: 91.22686771761481\n",
      "\n",
      "tensor(5.7051)\n",
      "tensor(5.7051)\n",
      "Iteration: 500. \n",
      "Test - Loss: 573.94287109375. Accuracy: 91.0958904109589\n",
      "Train -  Loss: 1496.5677490234375. Accuracy: 91.24971441626685\n",
      "\n",
      "tensor(5.7347)\n",
      "tensor(5.7347)\n",
      "Iteration: 600. \n",
      "Test - Loss: 568.8789672851562. Accuracy: 91.0958904109589\n",
      "Train -  Loss: 1475.14794921875. Accuracy: 91.36394790952707\n",
      "\n",
      "tensor(5.7531)\n",
      "tensor(5.7531)\n",
      "Iteration: 700. \n",
      "Test - Loss: 565.0568237304688. Accuracy: 91.21004566210046\n",
      "Train -  Loss: 1454.115478515625. Accuracy: 91.4781814027873\n",
      "\n",
      "tensor(5.7747)\n",
      "tensor(5.7747)\n",
      "Iteration: 800. \n",
      "Test - Loss: 561.4169921875. Accuracy: 91.21004566210046\n",
      "Train -  Loss: 1434.4417724609375. Accuracy: 91.59241489604752\n",
      "\n",
      "tensor(5.8070)\n",
      "tensor(5.8070)\n",
      "Iteration: 900. \n",
      "Test - Loss: 557.8565673828125. Accuracy: 91.21004566210046\n",
      "Train -  Loss: 1416.532958984375. Accuracy: 91.6381082933516\n",
      "\n",
      "tensor(5.8504)\n",
      "tensor(5.8504)\n",
      "Iteration: 1000. \n",
      "Test - Loss: 554.64599609375. Accuracy: 91.21004566210046\n",
      "Train -  Loss: 1400.3233642578125. Accuracy: 91.75234178661184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = torch.sigmoid(self.linear(x))\n",
    "        return outputs\n",
    "\n",
    "epochs = 1000\n",
    "input_dim = 420 \n",
    "output_dim = 1 \n",
    "learning_rate = 0.01\n",
    "\n",
    "model = LogisticRegression(input_dim,output_dim)\n",
    "\n",
    "criterion = nn.BCELoss(reduction='sum')\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "X_train, X_test = torch.Tensor(np.array(X_train)),torch.Tensor(np.array(X_test))\n",
    "y_train, y_test = torch.Tensor(np.array(y_train)),torch.Tensor(np.array(y_test))\n",
    "\n",
    "losses = []\n",
    "losses_test = []\n",
    "Iterations = []\n",
    "iter = 0\n",
    "for epoch in range(epochs):\n",
    "    x = X_train\n",
    "    labels = y_train\n",
    "    optimizer.zero_grad() \n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(torch.squeeze(outputs), torch.tensor(np.array(labels)))+pr.forward(pr,X_train,y_train)\n",
    "    loss.backward()  \n",
    "    optimizer.step() \n",
    "    \n",
    "    iter+=1\n",
    "    if iter%100==0:\n",
    "        # calculate Accuracy\n",
    "        with torch.no_grad():\n",
    "            # Calculating the loss and accuracy for the test dataset\n",
    "            correct_test = 0\n",
    "            total_test = 0\n",
    "            outputs_test = torch.squeeze(model(X_test))\n",
    "            loss_test = criterion(outputs_test, torch.tensor(np.array(y_test)))+pr.forward(pr,X_test,y_test)\n",
    "            print(pr.forward(pr,X_test,y_test))\n",
    "            \n",
    "            predicted_test = outputs_test.round().detach().numpy()\n",
    "            total_test += y_test.size(0)\n",
    "            correct_test += np.sum(predicted_test == y_test.detach().numpy())\n",
    "            accuracy_test = 100 * correct_test/total_test\n",
    "            losses_test.append(loss_test.item())\n",
    "            print(pr.forward(pr,X_test,y_test))\n",
    "            \n",
    "            # Calculating the loss and accuracy for the train dataset\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            total += y_train.size(0)\n",
    "            correct += np.sum(torch.squeeze(outputs).round().detach().numpy() == y_train.detach().numpy())\n",
    "            accuracy = 100 * correct/total\n",
    "            losses.append(loss.item())\n",
    "            Iterations.append(iter)\n",
    "            \n",
    "            print(f\"Iteration: {iter}. \\nTest - Loss: {loss_test.item()}. Accuracy: {accuracy_test}\")\n",
    "            print(f\"Train -  Loss: {loss.item()}. Accuracy: {accuracy}\\n\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
